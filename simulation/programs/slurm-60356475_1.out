Sun Oct 25 10:51:59 EDT 2020
c29a-s23.ufhpc
/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation/programs
This is task 1, which will do runs 1 to 2
/tmp/slurmd/job60356477/slurm_script: line 40: [: 0.5: integer expression expected
/tmp/slurmd/job60356477/slurm_script: line 41: [: 0.5: integer expression expected
/tmp/slurmd/job60356477/slurm_script: line 42: [: 0.5: integer expression expected

R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> what.to.do <- (commandArgs(TRUE))
> if(length(what.to.do)>0)
+ {
+   my.alpha <- as.numeric(as.character(unlist(strsplit(what.to.do[1],"="))[2]))
+ 	my.delta <- as.numeric(as.character(unlist(strsplit(what.to.do[2],"="))[2]))
+ 	my.qtest <- as.numeric(as.character(unlist(strsplit(what.to.do[3],"="))[2]))
+ 	my.qline <- as.numeric(as.character(unlist(strsplit(what.to.do[4],"="))[2]))
+ 	mult <- as.numeric(as.character(unlist(strsplit(what.to.do[5],"="))[2]))
+ 	myreads <- as.numeric(as.character(unlist(strsplit(what.to.do[6],"="))[2]))
+ 	simruns <- as.numeric(as.character(unlist(strsplit(what.to.do[7],"="))[2]))
+ 	out.file <- as.character(as.character(unlist(strsplit(what.to.do[8],"="))[2]))
+     nconditions<- as.numeric(as.character(unlist(strsplit(what.to.do[9],"="))[2]))
+ 
+ }
> 
> #It is horrible I know!
> #Temporarily we hardcode the number of replicates
> nreps<-3
> 
> #Removed set.seed(0) because always gave the same result!!!!!
> #set.seed(0)
> 
> #Delta is like alpha, but in the second environment (i.e. delta=1 is no AI in ENV2)
> 
> 
> ###################################################
> #
> # Try to generalize for n environments
> #
> ###################################################
> 
> seqcond<-paste("c",seq(1,nconditions),sep="")
> 
> 
> repsuffix<-paste0("_rep",seq(1,nreps))
> fornames1=paste("g1_",seqcond,sep="") #Genotype 1 given condition number
> fornames2 <- c("sampleprop", "mean", "q025", "q975", "Bayes_evidence", "AI_decision")
> fornames=paste(paste(rep(fornames1,each=length(fornames2)),fornames2,sep="_"),collapse=",")
> #The three possible alignment states: better to tester (G1?), better to line (G2?), equally good (both).
> #alnto<-c("g1","g2","Both")
> counttester<-as.vector(sapply(paste("counts_",seqcond,"_g1",sep=""),paste0,repsuffix))
> countline<-as.vector(sapply(paste("counts_",seqcond,"_g2",sep=""),paste0,repsuffix))
> countboth<-as.vector(sapply(paste("counts_",seqcond,"_both",sep=""),paste0,repsuffix))
> countheader<-paste(counttester,countline,countboth,sep=",",collapse=",")
> priorstester<-paste("prior_",seqcond,"_g1",sep="")
> priorsline<-paste("prior_",seqcond,"_g2",sep="")
> allpriors<-sort(c(priorstester,priorsline))
> seqreps<-paste(seqcond,"_num_reps",sep="")
> activeflag<-paste(seqcond,"flag_analyze",sep="_")
> firstheaders=paste(c("comparison","FEATURE_ID",
+                      seqreps,
+                      countheader,
+                       allpriors,
+ 					  activeflag),
+                       collapse=",")
> print(unlist(strsplit(firstheaders,",")))
 [1] "comparison"          "FEATURE_ID"          "c1_num_reps"        
 [4] "counts_c1_g1_rep1"   "counts_c1_g2_rep1"   "counts_c1_both_rep1"
 [7] "counts_c1_g1_rep2"   "counts_c1_g2_rep2"   "counts_c1_both_rep2"
[10] "counts_c1_g1_rep3"   "counts_c1_g2_rep3"   "counts_c1_both_rep3"
[13] "prior_c1_g1"         "prior_c1_g2"         "c1_flag_analyze"    
> headers<-firstheaders
> cat(headers, file=out.file, append=FALSE, sep="\n")
> 
> 
> #End of arguments and names copied from the scripts used for the analysis of real data
> 
> 
> 
> ##################################
> #
> # Simulation
> #
> ##################################
> print(simruns)
[1] 2
> for (aaa in 1:simruns)
+ {
+   #It simulates data according to a specific model (I need to check wich one)
+   #and compares the inference for different versions of the model
+   #
+   #Parameters of true model
+   allI<-rep(nreps,nconditions) #Number of replicates in each environment (we are currentyl stuck to having the same number of reps in the environments)
+   true_betas_row1 <- c(1,1.2,0.7)*myreads   #These are the biorep effets, the beta_i s
+   #At present we use true_betas that do not vary across conditions. This may be changed in the future
+   #When we were fixed to 2 environments we used different betas
+   true_betas_row2 <- c(1,1.3,0.8)*myreads
+   true_alpha <- my.alpha            #if different from 1 AI at environment 1 (Mated)
+   true_delta <- my.delta            #if different from 1 AI at environment 1 (Virgin)
+   true_gamma <- 1            #The current model assumes 1, but it used to be useful before
+   true_tau <- 1              #The current model assumes 1, but at some point we considered it different from 1
+ 
+   #If I well understand the first is q in tester and the second in line. q_row1 is enviornment1 and q_row2 environment 2
+   
+   allq<-matrix(rep(c(my.qtest,my.qline),nconditions),ncol=2,byrow=T)  
+   #q_row1 <- c(my.qtest, my.qline)
+   #q_row2 <- c(my.qtest, my.qline)
+   
+   true_phi <- 0.02           #Neg binomial dispersion parameter, the bigger it is the higher the variance=mu+phi mu^2 is
+ 
+   #xs <- ys <- zs <- rep(NA, sum(allI))
+ 
+   flaganalyze<- rep(1,nconditions)
+   for(loopc in 1:nconditions)
+ 	{
+ 		cat("loopc is",loopc,"\n")
+ 		means <- c(allq[loopc,1]/true_alpha, allq[loopc,2]*true_alpha, mult*((1-allq[loopc,1])/true_alpha+(1-allq[loopc,2])*true_alpha)*true_tau)
+ 		for(i in 1:allI[loopc])
+ 		{
+ 			xs <- rnbinom(1, size=1/true_phi, mu=means[1]*true_betas_row1[i])
+ 			ys <- rnbinom(1, size=1/true_phi, mu=means[2]*true_betas_row1[i])
+ 			zs <- rnbinom(1, size=1/true_phi, mu=means[3]*true_betas_row1[i])
+ 			# cat("xs of i",i,"is",xs[i],"\n")
+ 			# cat("true_betas_row1[i] is",true_betas_row1[i],"\n")
+ 			# cat("means[1] is",means[1],"\n")
+ 		if(loopc==1&i==1) mycounts<-paste(xs,ys,zs,sep=",") else mycounts<-paste(mycounts,xs,ys,zs,sep=",")
+ 		}	
+ 	}
+ 
+ 	cat("mycounts is",mycounts,"\n")
+ 	
+ 	out <- paste("line", "fusion_id", paste(allI,collapse=","),
+ 	          mycounts, 
+ 	          paste(as.vector(t(allq)),collapse=","), paste(flaganalyze,collapse=","), sep=",")
+ 	cat(out,file=out.file,append=TRUE,sep="\n")
+ }
loopc is 1 
mycounts is 157,29,51,203,38,68,125,22,32 
loopc is 1 
mycounts is 135,38,49,208,46,79,106,32,29 
> 
are_q_equal Y
qsim1 0.8
qmodel1 0.8

R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> what.to.do <- (commandArgs(TRUE))
> if(length(what.to.do)>0)
+ {
+   data.file <- as.character(unlist(strsplit(what.to.do[1],"="))[2])
+   q.model.g1 <- as.numeric(as.character(unlist(strsplit(what.to.do[2],"="))[2]))
+   q.model.g2 <- as.numeric(as.character(unlist(strsplit(what.to.do[3],"="))[2]))
+   stan.program <- as.character(unlist(strsplit(what.to.do[4],"="))[2])
+   niter <- as.numeric(as.character(unlist(strsplit(what.to.do[5],"="))[2]))
+   nburnin <- as.numeric(as.character(unlist(strsplit(what.to.do[6],"="))[2]))
+   save.sample.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[7],"="))[2]))
+   reporting.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[8],"="))[2]))
+   stepsize <- as.numeric(as.character(unlist(strsplit(what.to.do[9],"="))[2]))
+   nconditions<- as.numeric(as.character(unlist(strsplit(what.to.do[10],"="))[2]))
+ }
> 
> out.dir <- dirname(data.file)
> print(out.dir)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_not_null"
> 
> base.out<-paste(gsub(".csv","",basename(data.file)), 
+                                  stan.program,
+                                  'qmodel_g1', q.model.g1, 'qmodel_g2', q.model.g2, 
+                                  'iterations', niter, 'burnin', nburnin, 
+                                  'thin', save.sample.freq, 'refresh', reporting.freq, 
+                                  'stepsize', stepsize, sep="_")
> fileout <- paste(paste(out.dir, base.out, sep = "/"),".csv",sep="")
> print(fileout)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_not_null/out_alpha_0.5_delta_0.5_qsim_g1_0.8_qsim_g2_0.8_mult_1_myreads_100_simruns_2_stan2_qmodel_g1_0.8_qmodel_g2_0.8_iterations_6000_burnin_3000_thin_1_refresh_1000_stepsize_0.8.csv"
> 
> #########################
> #Trying to generalize to an arbitrary number of conditions
> #########################
> 
> seqcond<-paste("c",seq(1,nconditions),sep="")
> fornames1=paste("g1_",seqcond,sep="") #Genotype 1 given condition number
> fornames2 <- c("sampleprop", "mean", "q025", "q975", "Bayes_evidence", "AI_decision")
> fornames=paste(paste(rep(fornames1,each=length(fornames2)),fornames2,sep="_"),collapse=",")
> #The three possible alignment states: better to tester (G1?), better to line (G2?), equally good (both).
> #alnto<-c("g1","g2","Both")
> counttester<-paste("counts_",seqcond,"_g1",sep="")
> countline<-paste("counts_",seqcond,"_g2",sep="")
> countboth<-paste("counts_",seqcond,"_both",sep="")
> countheader<-paste(counttester,countline,countboth,sep=",",collapse=",")
> priorstester<-paste("prior_",seqcond,"_g1",sep="")
> priorsline<-paste("prior_",seqcond,"_g2",sep="")
> allpriors<-sort(c(priorstester,priorsline))
> seqreps<-paste(seqcond,"_num_reps",sep="")
> activeflag<-paste(seqcond,"flag_analyze",sep="_")
> firstheaders=paste(c("comparison","FEATURE_ID",
+                      seqreps,
+                      countheader,
+                       allpriors, 
+ 					  "H3_independence_Bayes_evidence"),
+                       collapse=",")
> 
> alpha_post_names<-paste(paste("alpha",seq(1,nconditions),"_postmean",sep=""),collapse=",")
> cat("alpha names are:",alpha_post_names,"\n")
alpha names are: alpha1_postmean 
> cat("firstheaders are:",firstheaders,"\n")
firstheaders are: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence 
> headers_out=paste(firstheaders,fornames,alpha_post_names,paste(activeflag,collapse=","),sep=",")
> cat("headers_out is:",headers_out,"\n")
headers_out is: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence,g1_c1_sampleprop,g1_c1_mean,g1_c1_q025,g1_c1_q975,g1_c1_Bayes_evidence,g1_c1_AI_decision,alpha1_postmean,c1_flag_analyze 
> cat(headers_out,file=fileout,append=FALSE,sep="\n")
> 
> 
> #End of arguments and names copied from the scripts used for the analysis of real data
> 
> #The special thing about this function is that it is able to accept a multiplicative factor for the estimation of the reads aligning on both genomes, to see how misspecification of that quantity affects results
> options(warn=1)
> 
> library("rstan")
Loading required package: StanHeaders
Loading required package: ggplot2
rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
> rstan_options(auto_write = FALSE)
> gam.mles.data <- function(x){
+   # CALCULATION OF THE MLES for gamma  GIVEN THE SAMPLE
+   n <- length(x)
+   xb <- mean(x)
+   xd <- mean(log(x))
+   s <- log(xb)-xd
+   a0 <- (3.0-s+sqrt((s-3.0)^2+24.0*s))/12.0/s
+   l <- 1
+   repeat{
+     ans <- (log(a0)-digamma(a0)-s)
+     a1 <- a0-ans/(1.0/a0-trigamma(a0))
+     if(abs(ans) <= 1.0e-7 | l >= 30){break}
+     a0 <- a1
+     l <- l+1}
+   ah <- a1; bh <- xb/a1
+   return(c(ah,bh))
+ }
> 
> #Computing prior hyperparameters for beta, the size effect
> prior_empBayes_forbeta <- function(xs,ys,zs){
+   #Function to compute the hyperparameters of the gamma distribution for
+   #beta_1,...beta_K~beta(a_beta,b_beta) with b_beta~gamma(a_b_beta,b_b_beta)
+   bbeta_est <- (xs+ys+zs)/2
+   bbeta_est[which(bbeta_est==0)] <- 0.1
+   tem <- gam.mles.data(bbeta_est) #MLE of the gamma function but it is parameterized so that E(x)=ab if x~gamma(a,b)
+   tem[1] <- min(max(tem[1],10^(-3)),10^5)
+   tem[2] <- min(max(tem[2],10^(-3)),10^5)  #Our gamma parameterization is E(x)=a/b
+   a_beta <- tem[1]
+   a_b_beta <- 2*tem[2]^(-1)#
+   b_b_beta <- 2
+   return(list(a_beta=a_beta, a_b_beta=a_b_beta, b_b_beta=b_b_beta))
+ }
> 
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ tibble  3.0.4     ✔ dplyr   1.0.2
✔ tidyr   1.1.2     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
✔ purrr   0.3.4     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ tidyr::extract() masks rstan::extract()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
> mydata <- as_tibble(read.csv(data.file))
> 
> for (gene in 1:nrow(mydata))
+ {
+   
+   nreps <- mydata[gene,] %>% dplyr::select(ends_with("num_reps"))
+   nconditions <- length(nreps)            #Number of environments
+   seqI<-nreps
+   allI<-as.vector(seqI)  
+   cat("seqI is")
+   print(seqI)
+   
+   xs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g1")))
+   ys <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g2")))
+   zs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("both")))
+   xactiveflag <- unlist(mydata[gene,] %>% dplyr::select(contains("flag_analyze")))
+   print(xs)
+   print(ys)
+   print(zs)
+   #If at least one flaganalyze is 0 we fill the results wiht NA and go to the next
+   if(prod(xactiveflag)==0)
+   {
+     howmanyNA<-length(unlist(strsplit(headers_out,",")))-2
+ 	out=paste("line", "fusion_id", rep(NA,howmanyNA,collapse=","),sep=",")
+   cat(out,file=fileout,append=TRUE,sep="\n")
+   next
+   }
+   q_sim <- matrix(unlist((mydata[gene, ]%>% dplyr::select(starts_with("prior")))), nrow=length(nreps), byrow =TRUE, ncol=2)
+   
+   hyper_beta <- prior_empBayes_forbeta(xs, ys, zs)
+   #Making the data ready for stan
+   datastan <- list(K = sum(seqI),                 #Total number of bioresps
+ 	    n_environment = nconditions,         #Number of environments, so far 2.
+ 	    xenv = rep(seq(1,length(seqI)),seqI),       #Environment index 
+ 	    xs = as.vector(xs),
+ 	    ys = as.vector(ys),
+ 	    zs = as.vector(zs),
+ 	    r = q_sim,  #matrix of systematic bias corrections
+ 	    a_beta = hyper_beta$a_beta,               #Set to MLE under the null model
+ 	    a_b_beta = hyper_beta$a_b_beta,           #b_beta~gamma(a_b_beta,b_b_beta)
+ 	    b_b_beta = hyper_beta$b_b_beta,
+ 	    a_overdispersion = 2.01,#1,
+ 	    b_overdispersion = 0.05 #100, #phi is apriori small, if inverse gamma is used prior mean b_phi/(a_phi-1)
+ 	 )
+   
+   starting_values  <-  function(){ ###Not actually needed according to Luis
+     out <- with(datastan, list(overdispersion=0.01, bbeta=xs+ys+zs, alpha=rep(1.0,n_environment)))
+     return(out)
+   }
+ 
+ 	totalcounts=
+ 	rbind(
+ 	xs=tapply(datastan$xs,FUN=sum,INDEX=datastan$xenv),
+ 	ys=tapply(datastan$ys,FUN=sum,INDEX=datastan$xenv),
+ 	zs=tapply(datastan$zs,FUN=sum,INDEX=datastan$xenv)
+ 	)
+   
+   cat("datastan is")
+   print(datastan)
+ 
+   fit1 <-rstan::stan(
+     file = "environmentalmodel2.stan", # Stan program
+ 	  data = datastan,    # named list of data
+ 	  chains = 1,             # number of Markov chains
+ 	  warmup = nburnin,          # number of warmup iterations per chain
+ 	  thin = save.sample.freq,
+ 	  iter = niter,            # total number of iterations per chain
+ 	  refresh = reporting.freq,             # no progress shown if this is 0
+ 	  init = "starting_values",
+ 	  control = list(adapt_delta = stepsize)  # The bigger the value the smaller the step size
+ 	  #pars=c("alpha","sigma_alpha")
+ 	  #c("bbeta","alpha","overdispersion","theta","sigma_alpha") 
+    )
+ 	
+    # fig.dir <- paste0(unlist(strsplit(out.dir, "/g3_sim_output"))[1], "/data_visualization")
+    # jpeg(paste0(fig.dir,"/diagnostic_plots_stan4c_", gsub(".csv", "", tail(unlist(strsplit(fileout, "/")), 1)),".jpeg"))
+    # rstan::pairs(fit1)
+    # dev.off()
+   
+   theta<-rstan::extract(fit1,pars="theta")$theta #Estimated proportion of reads aligning to tester in mated after adjusting for systematic bias
+   alpha<-rstan::extract(fit1,pars=c("alpha"))$alpha
+   Stanresults=matrix(NA,nrow=nconditions,ncol=4)
+   Bayes_AI_pvalue<-rep(NA,nconditions)
+   for(mystan in 1:nrow(Stanresults)) {
+     theta1<-theta[,mystan]
+     alpha1<-alpha[,mystan]
+     Stanresults[mystan,]<-c(mean(theta1), quantile(theta1,c(0.025,0.975)),2*min(mean(theta1>1/2),mean(theta1<1/2))) 
+     Bayes_AI_pvalue[mystan]<-2*min(c(mean(alpha1>1),mean(alpha1<1)))
+   }
+   colnames(Stanresults)=c("mean","q_025","q_975","AIbayesian-pva")
+   cat("Stanresults",Stanresults,"\n")
+   Stanresults[,"AIbayesian-pva"]
+   
+   for(repcond in 1:nconditions) {
+     theta1<-theta[,repcond]
+     smallStanres<-paste(round(totalcounts[row.names(totalcounts)=="xs",repcond]/(totalcounts[row.names(totalcounts)=="xs",repcond]+totalcounts[row.names(totalcounts)=="ys",repcond]),4),
+                         round(mean(theta1),4),
+                         paste(round(quantile(theta1,c(0.025,0.975)),4),collapse=","),
+                         round(Bayes_AI_pvalue[repcond],4),
+                         ifelse(Bayes_AI_pvalue[repcond]<0.05,1,0),sep=",")
+     if(repcond==1) fullStanres<-smallStanres else fullStanres<-paste(fullStanres,smallStanres,sep=",",collapse=",")
+   }
+   alpha1greateralpha2<-NA 
+   #alpha1greateralpha2 is the bayesian independence test. Only meaningful for two conditions
+   if(nconditions==2) {
+     alpha1greateralpha2<-round(min(mean(alpha[,1]>alpha[,2]),mean(alpha[,1]<alpha[,2]))*2,4)
+   }
+   
+   out=paste("line", "fusion_id", paste(allI,collapse=","), 
+             paste(apply(totalcounts,2,paste,collapse=","),collapse=","),
+             paste(t(datastan$r),collapse=","),
+             alpha1greateralpha2,
+             fullStanres,
+             paste(round(apply(alpha,2,mean),4),collapse=","),
+ 			paste(xactiveflag,collapse=","),
+             sep=",")
+   print(xactiveflag)
+   cat(out,file=fileout,append=TRUE,sep="\n")
+   print(unlist(strsplit(headers_out,",")))
+   print(unlist(strsplit(out,",")))
+ }
seqI is# A tibble: 1 x 1
  c1_num_reps
        <int>
1           3
counts_c1_g1_rep1 counts_c1_g1_rep2 counts_c1_g1_rep3 
              157               203               125 
counts_c1_g2_rep1 counts_c1_g2_rep2 counts_c1_g2_rep3 
               29                38                22 
counts_c1_both_rep1 counts_c1_both_rep2 counts_c1_both_rep3 
                 51                  68                  32 
datastan is$K
[1] 3

$n_environment
[1] 1

$xenv
[1] 1 1 1

$xs
[1] 157 203 125

$ys
[1] 29 38 22

$zs
[1] 51 68 32

$r
     [,1] [,2]
[1,]  0.8  0.8

$a_beta
[1] 20.46549

$a_b_beta
[1] 0.3387391

$b_b_beta
[1] 2

$a_overdispersion
[1] 2.01

$b_overdispersion
[1] 0.05


SAMPLING FOR MODEL 'environmentalmodel2' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 2.9e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 1: Iteration: 1000 / 6000 [ 16%]  (Warmup)
Chain 1: Iteration: 2000 / 6000 [ 33%]  (Warmup)
Chain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 1: Iteration: 4000 / 6000 [ 66%]  (Sampling)
Chain 1: Iteration: 5000 / 6000 [ 83%]  (Sampling)
Chain 1: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.184457 seconds (Warm-up)
Chain 1:                0.198138 seconds (Sampling)
Chain 1:                0.382595 seconds (Total)
Chain 1: 
Stanresults 0.8214806 0.7675287 0.863147 0 
c1_flag_analyze 
              1 
 [1] "comparison"                     "FEATURE_ID"                    
 [3] "c1_num_reps"                    "counts_c1_g1"                  
 [5] "counts_c1_g2"                   "counts_c1_both"                
 [7] "prior_c1_g1"                    "prior_c1_g2"                   
 [9] "H3_independence_Bayes_evidence" "g1_c1_sampleprop"              
[11] "g1_c1_mean"                     "g1_c1_q025"                    
[13] "g1_c1_q975"                     "g1_c1_Bayes_evidence"          
[15] "g1_c1_AI_decision"              "alpha1_postmean"               
[17] "c1_flag_analyze"               
 [1] "line"      "fusion_id" "3"         "485"       "89"        "151"      
 [7] "0.8"       "0.8"       "NA"        "0.8449"    "0.8215"    "0.7675"   
[13] "0.8631"    "0"         "1"         "0.4657"    "1"        
seqI is# A tibble: 1 x 1
  c1_num_reps
        <int>
1           3
counts_c1_g1_rep1 counts_c1_g1_rep2 counts_c1_g1_rep3 
              135               208               106 
counts_c1_g2_rep1 counts_c1_g2_rep2 counts_c1_g2_rep3 
               38                46                32 
counts_c1_both_rep1 counts_c1_both_rep2 counts_c1_both_rep3 
                 49                  79                  29 
datastan is$K
[1] 3

$n_environment
[1] 1

$xenv
[1] 1 1 1

$xs
[1] 135 208 106

$ys
[1] 38 46 32

$zs
[1] 49 79 29

$r
     [,1] [,2]
[1,]  0.8  0.8

$a_beta
[1] 12.51769

$a_b_beta
[1] 0.2080503

$b_b_beta
[1] 2

$a_overdispersion
[1] 2.01

$b_overdispersion
[1] 0.05


SAMPLING FOR MODEL 'environmentalmodel2' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.9e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 1: Iteration: 1000 / 6000 [ 16%]  (Warmup)
Chain 1: Iteration: 2000 / 6000 [ 33%]  (Warmup)
Chain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 1: Iteration: 4000 / 6000 [ 66%]  (Sampling)
Chain 1: Iteration: 5000 / 6000 [ 83%]  (Sampling)
Chain 1: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.182853 seconds (Warm-up)
Chain 1:                0.195237 seconds (Sampling)
Chain 1:                0.37809 seconds (Total)
Chain 1: 
Stanresults 0.7707884 0.7057251 0.8234632 0 
c1_flag_analyze 
              1 
 [1] "comparison"                     "FEATURE_ID"                    
 [3] "c1_num_reps"                    "counts_c1_g1"                  
 [5] "counts_c1_g2"                   "counts_c1_both"                
 [7] "prior_c1_g1"                    "prior_c1_g2"                   
 [9] "H3_independence_Bayes_evidence" "g1_c1_sampleprop"              
[11] "g1_c1_mean"                     "g1_c1_q025"                    
[13] "g1_c1_q975"                     "g1_c1_Bayes_evidence"          
[15] "g1_c1_AI_decision"              "alpha1_postmean"               
[17] "c1_flag_analyze"               
 [1] "line"      "fusion_id" "3"         "449"       "116"       "157"      
 [7] "0.8"       "0.8"       "NA"        "0.7947"    "0.7708"    "0.7057"   
[13] "0.8235"    "0"         "1"         "0.5452"    "1"        
> 
are_q_equal Y
qsim1 0.8
qmodel1 0.8

R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> what.to.do <- (commandArgs(TRUE))
> if(length(what.to.do)>0)
+ {
+   data.file <- as.character(as.character(unlist(strsplit(what.to.do[1],"="))[2]))
+   q.model.g1 <- as.numeric(as.character(unlist(strsplit(what.to.do[2],"="))[2]))
+   q.model.g2 <- as.numeric(unlist(strsplit(what.to.do[3],"="))[2])
+   stan.program <- as.character(unlist(strsplit(what.to.do[4],"="))[2])
+   niter <- as.numeric(as.character(unlist(strsplit(what.to.do[5],"="))[2]))
+   nburnin <- as.numeric(as.character(unlist(strsplit(what.to.do[6],"="))[2]))
+   save.sample.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[7],"="))[2]))
+   reporting.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[8],"="))[2]))
+   stepsize <- as.numeric(as.character(unlist(strsplit(what.to.do[9],"="))[2]))
+   nconditions<- as.numeric(as.character(unlist(strsplit(what.to.do[10],"="))[2]))
+ }
> 
> out.dir <- dirname(data.file)
> print(out.dir)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_not_null"
> 
> base.out<-paste(gsub(".csv","",basename(data.file)), 
+                                  stan.program,
+                                  'qmodel_g1', q.model.g1, 'qmodel_g2', q.model.g2, 
+                                  'iterations', niter, 'burnin', nburnin, 
+                                  'thin', save.sample.freq, 'refresh', reporting.freq, 
+                                  'stepsize', stepsize, sep="_")
> fileout <- paste(paste(out.dir, base.out, sep = "/"),".csv",sep="")
> print(fileout)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_not_null/out_alpha_0.5_delta_0.5_qsim_g1_0.8_qsim_g2_0.8_mult_1_myreads_100_simruns_2_stan4c_qmodel_g1_0.8_qmodel_g2_0.8_iterations_6000_burnin_3000_thin_1_refresh_1000_stepsize_0.99.csv"
> 
> #########################
> #Trying to generalize to an arbitrary number of conditions
> #########################
> 
> seqcond<-paste("c",seq(1,nconditions),sep="")
> fornames1=paste("g1_",seqcond,sep="") #Tester given condition
> fornames2 <- c("sampleprop", "mean", "q025", "q975", "Bayes_evidence", "AI_decision")
> fornames=paste(paste(rep(fornames1,each=length(fornames2)),fornames2,sep="_"),collapse=",")
> #The three possible alignment states: better to tester (G1?), better to line (G2?), equally good (both).
> #alnto<-c("g1","g2","Both")
> counttester<-paste("counts_",seqcond,"_g1",sep="")
> countline<-paste("counts_",seqcond,"_g2",sep="")
> countboth<-paste("counts_",seqcond,"_both",sep="")
> countheader<-paste(counttester,countline,countboth,sep=",",collapse=",")
> priorstester<-paste("prior_",seqcond,"_g1",sep="")
> priorsline<-paste("prior_",seqcond,"_g2",sep="")
> allpriors<-sort(c(priorstester,priorsline))
> seqreps<-paste(seqcond,"_num_reps",sep="")
> activeflag<-paste(seqcond,"flag_analyze",sep="_")
> firstheaders=paste(c("comparison","FEATURE_ID",
+                      seqreps,
+                      countheader,
+                       allpriors, 
+ 					  "H3_independence_Bayes_evidence",
+ 					  "probofsameAI"),
+                       collapse=",")
> 
> alpha_post_names<-paste(paste("alpha",seq(1,nconditions),"_postmean",sep=""),collapse=",")
> cat("alpha names are:",alpha_post_names,"\n")
alpha names are: alpha1_postmean 
> cat("stan4 firstheaders are:",firstheaders,"\n")
stan4 firstheaders are: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence,probofsameAI 
> headers_out=paste(firstheaders,fornames,alpha_post_names,"sigma_alpha_mean","sigma_alpha_0.5","sigma_alpha_0.95",paste(activeflag,collapse=","),sep=",")
> cat("stan4 headers_out is:",headers_out,"\n")
stan4 headers_out is: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence,probofsameAI,g1_c1_sampleprop,g1_c1_mean,g1_c1_q025,g1_c1_q975,g1_c1_Bayes_evidence,g1_c1_AI_decision,alpha1_postmean,sigma_alpha_mean,sigma_alpha_0.5,sigma_alpha_0.95,c1_flag_analyze 
> cat(headers_out,file=fileout,append=FALSE,sep="\n")
> 
> 
> #End of arguments and names copied from the scripts used for the analysis of real data
> 
> #The special thing about this function is that it is able to accept a multiplicative factor for the estimation of the reads aligning on both genomes, to see how misspecification of that quantity affects results
> options(warn=1)
> 
> library("rstan")
Loading required package: StanHeaders
Loading required package: ggplot2
rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
> rstan_options(auto_write = FALSE)
> gam.mles.data <- function(x){
+   # CALCULATION OF THE MLES for gamma  GIVEN THE SAMPLE
+   n <- length(x)
+   xb <- mean(x)
+   xd <- mean(log(x))
+   s <- log(xb)-xd
+   a0 <- (3.0-s+sqrt((s-3.0)^2+24.0*s))/12.0/s
+   l <- 1
+   repeat{
+     ans <- (log(a0)-digamma(a0)-s)
+     a1 <- a0-ans/(1.0/a0-trigamma(a0))
+     if(abs(ans) <= 1.0e-7 | l >= 30){break}
+     a0 <- a1
+     l <- l+1}
+   ah <- a1; bh <- xb/a1
+   return(c(ah,bh))
+ }
> 
> #Computing prior hyperparameters for beta, the size effect
> prior_empBayes_forbeta <- function(xs,ys,zs){
+   #Function to compute the hyperparameters of the gamma distribution for
+   #beta_1,...beta_K~beta(a_beta,b_beta) with b_beta~gamma(a_b_beta,b_b_beta)
+   bbeta_est <- (xs+ys+zs)/2
+   bbeta_est[which(bbeta_est==0)] <- 0.1
+   tem <- gam.mles.data(bbeta_est) #MLE of the gamma function but it is parameterized so that E(x)=ab if x~gamma(a,b)
+   tem[1] <- min(max(tem[1],10^(-3)),10^5)
+   tem[2] <- min(max(tem[2],10^(-3)),10^5)  #Our gamma parameterization is E(x)=a/b
+   a_beta <- tem[1]
+   a_b_beta <- 2*tem[2]^(-1)#
+   b_b_beta <- 2
+   return(list(a_beta=a_beta, a_b_beta=a_b_beta, b_b_beta=b_b_beta))
+ }
> 
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ tibble  3.0.4     ✔ dplyr   1.0.2
✔ tidyr   1.1.2     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
✔ purrr   0.3.4     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ tidyr::extract() masks rstan::extract()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
> mydata <- as_tibble(read.csv(data.file))
> 
> for (gene in 1:nrow(mydata))
+ {
+   
+   nreps <- mydata[gene,] %>% dplyr::select(ends_with("num_reps"))
+   nconditions <- length(nreps)            #Number of environments
+   seqI<-nreps
+   allI<-as.vector(seqI)  
+   cat("seqI is")
+   print(seqI)
+  
+   xs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g1")))
+   ys <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g2")))
+   zs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("both")))
+   xactiveflag <- unlist(mydata[gene,] %>% dplyr::select(contains("flag_analyze")))
+   print(xs)
+   print(ys)
+   print(zs)
+   #If at least one flaganalyze is 0 we fill the results wiht NA and go to the next
+   if(prod(xactiveflag)==0)
+   {
+     howmanyNA<-length(unlist(strsplit(headers_out,",")))-2
+ 	out=paste("line", "fusion_id", rep(NA,howmanyNA,collapse=","),sep=",")
+     cat(out,file=fileout,append=TRUE,sep="\n")
+     next
+   }
+   q_sim <- matrix(unlist((mydata[gene, ]%>% dplyr::select(starts_with("prior")))), nrow=length(nreps), byrow =TRUE, ncol=2)
+   
+   hyper_beta <- prior_empBayes_forbeta(xs, ys, zs)
+   #Making the data ready for stan
+   datastan <- list(K = sum(seqI),                 #Total number of bioresps
+ 	    n_environment = nconditions,         #Number of environments, so far 2.
+ 	    xenv = rep(seq(1,length(seqI)),seqI),       #Environment index 
+ 	    xs = as.vector(xs),
+ 	    ys = as.vector(ys),
+ 	    zs = as.vector(zs),
+ 	    r = q_sim,  #matrix of systematic bias corrections
+ 	    a_beta = hyper_beta$a_beta,               #Set to MLE under the null model
+ 	    a_b_beta = hyper_beta$a_b_beta,           #b_beta~gamma(a_b_beta,b_b_beta)
+ 	    b_b_beta = hyper_beta$b_b_beta,
+ 	    a_overdispersion = 2.01,#1,
+ 	    b_overdispersion = 0.05 #100, #phi is apriori small, if inverse gamma is used prior mean b_phi/(a_phi-1)
+ 	 )
+   
+   starting_values  <-  function(){ ###Not actually needed according to Luis
+     out <- with(datastan, list(overdispersion=0.01, bbeta=xs+ys+zs, alpha=rep(1.0,n_environment)))
+     return(out)
+   }
+ 
+ 	totalcounts=
+ 	rbind(
+ 	xs=tapply(datastan$xs,FUN=sum,INDEX=datastan$xenv),
+ 	ys=tapply(datastan$ys,FUN=sum,INDEX=datastan$xenv),
+ 	zs=tapply(datastan$zs,FUN=sum,INDEX=datastan$xenv)
+ 	)
+   
+   datastan4c <- datastan
+   datastan4c$c_sigma_alpha <- c(NA,0.01760,0.01472,0.01343,0.01265 )[datastan4c$n_environment]#Constants depends on number of environments
+   cat("datastan is")
+   print(datastan4c)
+ 
+   fit1 <-rstan::stan(
+     file = "environmentalmodel4c.stan", # Stan program
+ 	  data = datastan4c,    # named list of data
+ 	  chains = 1,             # number of Markov chains
+ 	  warmup = nburnin,          # number of warmup iterations per chain
+ 	  thin = save.sample.freq,
+ 	  iter = niter,            # total number of iterations per chain
+ 	  refresh = reporting.freq,             # no progress shown
+ 	  init = "starting_values",
+ 	  control = list(adapt_delta = stepsize)  # The bigger the value the smaller the step size
+ 	  #pars=c("alpha","sigma_alpha")
+ 	  #c("bbeta","alpha","overdispersion","theta","sigma_alpha") 
+    )
+ 	
+    # fig.dir <- paste0(unlist(strsplit(out.dir, "/g3_sim_output"))[1], "/data_visualization")
+    # jpeg(paste0(fig.dir,"/diagnostic_plots_stan4c_", gsub(".csv", "", tail(unlist(strsplit(fileout, "/")), 1)),".jpeg"))
+    # rstan::pairs(fit1)
+    # dev.off()
+   
+ 	palphasequal <- rstan::extract(fit1,pars=c("palphasequal"))$palphasequal
+ 	theta <- rstan::extract(fit1,pars="theta")$theta #Estimated proportion of reads aligning to tester in mated after adjusting for systematic bias
+ 	alpha <- rstan::extract(fit1,pars=c("alpha"))$alpha
+ 	sigma_alpha <- rstan::extract(fit1,pars=c("sigma_alpha"))$sigma_alpha
+ 	
+ 	Stanresults <- matrix(NA,nrow=nconditions,ncol=4)
+ 	Bayes_AI_pvalue <- rep(NA,nconditions)
+ 	for(mystan in 1:nrow(Stanresults)) {
+ 	  theta1 <- theta[,mystan]
+ 	  alpha1 <- alpha[,mystan]
+     Stanresults[mystan,]<-c(mean(theta1), quantile(theta1,c(0.025,0.975)),2*min(mean(theta1>1/2),mean(theta1<1/2))) 
+ 	Bayes_AI_pvalue[mystan] <- 2*min(c(mean(alpha1>1), mean(alpha1<1)))
+ 	} 
+ 	
+ 	colnames(Stanresults) <- c("mean", "q_025", "q_975", "AIbayesian-pval")
+ 	cat("Stanresults",Stanresults,"\n")
+ 	Stanresults[,"AIbayesian-pval"]
+ 
+ 	sigma_alpha_out <- c(mean(sigma_alpha), quantile(sigma_alpha, c(0.5,0.95))) #POSSIBLE bug: c(0.5,0.95) or c(0.05,0.95)? 
+ 
+ 	for(repcond in 1:nconditions) {
+ 	  theta1 <- theta[,repcond]
+ 	  smallStanres <- paste(round(totalcounts[row.names(totalcounts)=="xs", repcond]/(totalcounts[row.names(totalcounts)=="xs", repcond] + totalcounts[row.names(totalcounts)=="ys", repcond]), 4),
+ 	                        round(mean(theta1), 4),
+ 	                        paste(round(quantile(theta1, c(0.025,0.975)), 4), collapse=","),
+ 	                        round(Bayes_AI_pvalue[repcond], 4), 
+ 	                        ifelse(Bayes_AI_pvalue[repcond] < 0.05, 1, 0), sep=",")
+ 	  if(repcond==1) fullStanres <- smallStanres else fullStanres <- paste(fullStanres, smallStanres, sep=",", collapse=",")
+ 	}
+ 	
+ 	alpha1greateralpha2 <- NA
+ 	#alpha1greateralpha2 is the bayesian independence test. Only meaningful for two conditions
+ 	if(nconditions==2) {
+ 	  alpha1greateralpha2 <- min(tem<-mean(alpha[,1]-alpha[,2]<0),1-tem)*2
+ 	}
+ 
+ 	probofsameAI <- mean(palphasequal)    
+ 	
+ 	totalcounts <- rbind(xs <- tapply(datastan$xs, FUN=sum, INDEX=datastan$xenv),
+ 	                     ys <- tapply(datastan$ys, FUN=sum, INDEX=datastan$xenv),
+ 	                     zs <- tapply(datastan$zs, FUN=sum, INDEX=datastan$xenv))
+ 	
+ 	out <- paste("line", "fusion_id", paste(allI,collapse=","),
+ 	             paste(apply(totalcounts, 2, paste, collapse=","), collapse=","),
+ 				 paste(t(datastan$r),collapse=","),
+ 	             alpha1greateralpha2,
+ 	             probofsameAI,
+ 	             fullStanres,
+ 	             paste(round(apply(alpha,2,mean),4),collapse=","),
+ 	             paste(round(sigma_alpha_out,6),collapse=","),
+ 				 paste(xactiveflag,collapse=","),
+ 	             sep=",")
+     print(xactiveflag)
+ 	cat(out, file=fileout, append=TRUE, sep="\n")
+     print(unlist(strsplit(headers_out,",")))
+     print(unlist(strsplit(out,",")))
+ 
+ }
seqI is# A tibble: 1 x 1
  c1_num_reps
        <int>
1           3
counts_c1_g1_rep1 counts_c1_g1_rep2 counts_c1_g1_rep3 
              157               203               125 
counts_c1_g2_rep1 counts_c1_g2_rep2 counts_c1_g2_rep3 
               29                38                22 
counts_c1_both_rep1 counts_c1_both_rep2 counts_c1_both_rep3 
                 51                  68                  32 
datastan is$K
[1] 3

$n_environment
[1] 1

$xenv
[1] 1 1 1

$xs
[1] 157 203 125

$ys
[1] 29 38 22

$zs
[1] 51 68 32

$r
     [,1] [,2]
[1,]  0.8  0.8

$a_beta
[1] 20.46549

$a_b_beta
[1] 0.3387391

$b_b_beta
[1] 2

$a_overdispersion
[1] 2.01

$b_overdispersion
[1] 0.05

$c_sigma_alpha
[1] NA

Error in FUN(X[[i]], ...) : 
  Stan does not support NA (in c_sigma_alpha) in data
failed to preprocess the data; sampling not done
Stan model 'environmentalmodel4c' does not contain samples.
Stan model 'environmentalmodel4c' does not contain samples.
Stan model 'environmentalmodel4c' does not contain samples.
Stan model 'environmentalmodel4c' does not contain samples.
Warning in mean.default(theta1) :
  argument is not numeric or logical: returning NA
Stanresults NA NA NA NaN 
Warning in mean.default(sigma_alpha) :
  argument is not numeric or logical: returning NA
Warning in mean.default(theta1) :
  argument is not numeric or logical: returning NA
Warning in mean.default(palphasequal) :
  argument is not numeric or logical: returning NA
Error in apply(alpha, 2, mean) : dim(X) must have a positive length
Calls: paste -> paste -> apply
Execution halted

R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> what.to.do <- (commandArgs(TRUE))
> if(length(what.to.do)>0)
+ {
+   my.alpha <- as.numeric(as.character(unlist(strsplit(what.to.do[1],"="))[2]))
+ 	my.delta <- as.numeric(as.character(unlist(strsplit(what.to.do[2],"="))[2]))
+ 	my.qtest <- as.numeric(as.character(unlist(strsplit(what.to.do[3],"="))[2]))
+ 	my.qline <- as.numeric(as.character(unlist(strsplit(what.to.do[4],"="))[2]))
+ 	mult <- as.numeric(as.character(unlist(strsplit(what.to.do[5],"="))[2]))
+ 	myreads <- as.numeric(as.character(unlist(strsplit(what.to.do[6],"="))[2]))
+ 	simruns <- as.numeric(as.character(unlist(strsplit(what.to.do[7],"="))[2]))
+ 	out.file <- as.character(as.character(unlist(strsplit(what.to.do[8],"="))[2]))
+     nconditions<- as.numeric(as.character(unlist(strsplit(what.to.do[9],"="))[2]))
+ 
+ }
> 
> #It is horrible I know!
> #Temporarily we hardcode the number of replicates
> nreps<-3
> 
> #Removed set.seed(0) because always gave the same result!!!!!
> #set.seed(0)
> 
> #Delta is like alpha, but in the second environment (i.e. delta=1 is no AI in ENV2)
> 
> 
> ###################################################
> #
> # Try to generalize for n environments
> #
> ###################################################
> 
> seqcond<-paste("c",seq(1,nconditions),sep="")
> 
> 
> repsuffix<-paste0("_rep",seq(1,nreps))
> fornames1=paste("g1_",seqcond,sep="") #Genotype 1 given condition number
> fornames2 <- c("sampleprop", "mean", "q025", "q975", "Bayes_evidence", "AI_decision")
> fornames=paste(paste(rep(fornames1,each=length(fornames2)),fornames2,sep="_"),collapse=",")
> #The three possible alignment states: better to tester (G1?), better to line (G2?), equally good (both).
> #alnto<-c("g1","g2","Both")
> counttester<-as.vector(sapply(paste("counts_",seqcond,"_g1",sep=""),paste0,repsuffix))
> countline<-as.vector(sapply(paste("counts_",seqcond,"_g2",sep=""),paste0,repsuffix))
> countboth<-as.vector(sapply(paste("counts_",seqcond,"_both",sep=""),paste0,repsuffix))
> countheader<-paste(counttester,countline,countboth,sep=",",collapse=",")
> priorstester<-paste("prior_",seqcond,"_g1",sep="")
> priorsline<-paste("prior_",seqcond,"_g2",sep="")
> allpriors<-sort(c(priorstester,priorsline))
> seqreps<-paste(seqcond,"_num_reps",sep="")
> activeflag<-paste(seqcond,"flag_analyze",sep="_")
> firstheaders=paste(c("comparison","FEATURE_ID",
+                      seqreps,
+                      countheader,
+                       allpriors,
+ 					  activeflag),
+                       collapse=",")
> print(unlist(strsplit(firstheaders,",")))
 [1] "comparison"          "FEATURE_ID"          "c1_num_reps"        
 [4] "counts_c1_g1_rep1"   "counts_c1_g2_rep1"   "counts_c1_both_rep1"
 [7] "counts_c1_g1_rep2"   "counts_c1_g2_rep2"   "counts_c1_both_rep2"
[10] "counts_c1_g1_rep3"   "counts_c1_g2_rep3"   "counts_c1_both_rep3"
[13] "prior_c1_g1"         "prior_c1_g2"         "c1_flag_analyze"    
> headers<-firstheaders
> cat(headers, file=out.file, append=FALSE, sep="\n")
> 
> 
> #End of arguments and names copied from the scripts used for the analysis of real data
> 
> 
> 
> ##################################
> #
> # Simulation
> #
> ##################################
> print(simruns)
[1] 2
> for (aaa in 1:simruns)
+ {
+   #It simulates data according to a specific model (I need to check wich one)
+   #and compares the inference for different versions of the model
+   #
+   #Parameters of true model
+   allI<-rep(nreps,nconditions) #Number of replicates in each environment (we are currentyl stuck to having the same number of reps in the environments)
+   true_betas_row1 <- c(1,1.2,0.7)*myreads   #These are the biorep effets, the beta_i s
+   #At present we use true_betas that do not vary across conditions. This may be changed in the future
+   #When we were fixed to 2 environments we used different betas
+   true_betas_row2 <- c(1,1.3,0.8)*myreads
+   true_alpha <- my.alpha            #if different from 1 AI at environment 1 (Mated)
+   true_delta <- my.delta            #if different from 1 AI at environment 1 (Virgin)
+   true_gamma <- 1            #The current model assumes 1, but it used to be useful before
+   true_tau <- 1              #The current model assumes 1, but at some point we considered it different from 1
+ 
+   #If I well understand the first is q in tester and the second in line. q_row1 is enviornment1 and q_row2 environment 2
+   
+   allq<-matrix(rep(c(my.qtest,my.qline),nconditions),ncol=2,byrow=T)  
+   #q_row1 <- c(my.qtest, my.qline)
+   #q_row2 <- c(my.qtest, my.qline)
+   
+   true_phi <- 0.02           #Neg binomial dispersion parameter, the bigger it is the higher the variance=mu+phi mu^2 is
+ 
+   #xs <- ys <- zs <- rep(NA, sum(allI))
+ 
+   flaganalyze<- rep(1,nconditions)
+   for(loopc in 1:nconditions)
+ 	{
+ 		cat("loopc is",loopc,"\n")
+ 		means <- c(allq[loopc,1]/true_alpha, allq[loopc,2]*true_alpha, mult*((1-allq[loopc,1])/true_alpha+(1-allq[loopc,2])*true_alpha)*true_tau)
+ 		for(i in 1:allI[loopc])
+ 		{
+ 			xs <- rnbinom(1, size=1/true_phi, mu=means[1]*true_betas_row1[i])
+ 			ys <- rnbinom(1, size=1/true_phi, mu=means[2]*true_betas_row1[i])
+ 			zs <- rnbinom(1, size=1/true_phi, mu=means[3]*true_betas_row1[i])
+ 			# cat("xs of i",i,"is",xs[i],"\n")
+ 			# cat("true_betas_row1[i] is",true_betas_row1[i],"\n")
+ 			# cat("means[1] is",means[1],"\n")
+ 		if(loopc==1&i==1) mycounts<-paste(xs,ys,zs,sep=",") else mycounts<-paste(mycounts,xs,ys,zs,sep=",")
+ 		}	
+ 	}
+ 
+ 	cat("mycounts is",mycounts,"\n")
+ 	
+ 	out <- paste("line", "fusion_id", paste(allI,collapse=","),
+ 	          mycounts, 
+ 	          paste(as.vector(t(allq)),collapse=","), paste(flaganalyze,collapse=","), sep=",")
+ 	cat(out,file=out.file,append=TRUE,sep="\n")
+ }
loopc is 1 
mycounts is 48,163,72,39,200,60,22,120,24 
loopc is 1 
mycounts is 31,188,71,43,213,64,48,81,32 
> 
are_q_equal Y
qsim1 0.8
qmodel1 0.8

R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> what.to.do <- (commandArgs(TRUE))
> if(length(what.to.do)>0)
+ {
+   data.file <- as.character(unlist(strsplit(what.to.do[1],"="))[2])
+   q.model.g1 <- as.numeric(as.character(unlist(strsplit(what.to.do[2],"="))[2]))
+   q.model.g2 <- as.numeric(as.character(unlist(strsplit(what.to.do[3],"="))[2]))
+   stan.program <- as.character(unlist(strsplit(what.to.do[4],"="))[2])
+   niter <- as.numeric(as.character(unlist(strsplit(what.to.do[5],"="))[2]))
+   nburnin <- as.numeric(as.character(unlist(strsplit(what.to.do[6],"="))[2]))
+   save.sample.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[7],"="))[2]))
+   reporting.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[8],"="))[2]))
+   stepsize <- as.numeric(as.character(unlist(strsplit(what.to.do[9],"="))[2]))
+   nconditions<- as.numeric(as.character(unlist(strsplit(what.to.do[10],"="))[2]))
+ }
> 
> out.dir <- dirname(data.file)
> print(out.dir)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_null"
> 
> base.out<-paste(gsub(".csv","",basename(data.file)), 
+                                  stan.program,
+                                  'qmodel_g1', q.model.g1, 'qmodel_g2', q.model.g2, 
+                                  'iterations', niter, 'burnin', nburnin, 
+                                  'thin', save.sample.freq, 'refresh', reporting.freq, 
+                                  'stepsize', stepsize, sep="_")
> fileout <- paste(paste(out.dir, base.out, sep = "/"),".csv",sep="")
> print(fileout)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_null/out_alpha_2_delta_2_qsim_g1_0.8_qsim_g2_0.8_mult_1_myreads_100_simruns_2_stan2_qmodel_g1_0.8_qmodel_g2_0.8_iterations_6000_burnin_3000_thin_1_refresh_1000_stepsize_0.8.csv"
> 
> #########################
> #Trying to generalize to an arbitrary number of conditions
> #########################
> 
> seqcond<-paste("c",seq(1,nconditions),sep="")
> fornames1=paste("g1_",seqcond,sep="") #Genotype 1 given condition number
> fornames2 <- c("sampleprop", "mean", "q025", "q975", "Bayes_evidence", "AI_decision")
> fornames=paste(paste(rep(fornames1,each=length(fornames2)),fornames2,sep="_"),collapse=",")
> #The three possible alignment states: better to tester (G1?), better to line (G2?), equally good (both).
> #alnto<-c("g1","g2","Both")
> counttester<-paste("counts_",seqcond,"_g1",sep="")
> countline<-paste("counts_",seqcond,"_g2",sep="")
> countboth<-paste("counts_",seqcond,"_both",sep="")
> countheader<-paste(counttester,countline,countboth,sep=",",collapse=",")
> priorstester<-paste("prior_",seqcond,"_g1",sep="")
> priorsline<-paste("prior_",seqcond,"_g2",sep="")
> allpriors<-sort(c(priorstester,priorsline))
> seqreps<-paste(seqcond,"_num_reps",sep="")
> activeflag<-paste(seqcond,"flag_analyze",sep="_")
> firstheaders=paste(c("comparison","FEATURE_ID",
+                      seqreps,
+                      countheader,
+                       allpriors, 
+ 					  "H3_independence_Bayes_evidence"),
+                       collapse=",")
> 
> alpha_post_names<-paste(paste("alpha",seq(1,nconditions),"_postmean",sep=""),collapse=",")
> cat("alpha names are:",alpha_post_names,"\n")
alpha names are: alpha1_postmean 
> cat("firstheaders are:",firstheaders,"\n")
firstheaders are: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence 
> headers_out=paste(firstheaders,fornames,alpha_post_names,paste(activeflag,collapse=","),sep=",")
> cat("headers_out is:",headers_out,"\n")
headers_out is: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence,g1_c1_sampleprop,g1_c1_mean,g1_c1_q025,g1_c1_q975,g1_c1_Bayes_evidence,g1_c1_AI_decision,alpha1_postmean,c1_flag_analyze 
> cat(headers_out,file=fileout,append=FALSE,sep="\n")
> 
> 
> #End of arguments and names copied from the scripts used for the analysis of real data
> 
> #The special thing about this function is that it is able to accept a multiplicative factor for the estimation of the reads aligning on both genomes, to see how misspecification of that quantity affects results
> options(warn=1)
> 
> library("rstan")
Loading required package: StanHeaders
Loading required package: ggplot2
rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
> rstan_options(auto_write = FALSE)
> gam.mles.data <- function(x){
+   # CALCULATION OF THE MLES for gamma  GIVEN THE SAMPLE
+   n <- length(x)
+   xb <- mean(x)
+   xd <- mean(log(x))
+   s <- log(xb)-xd
+   a0 <- (3.0-s+sqrt((s-3.0)^2+24.0*s))/12.0/s
+   l <- 1
+   repeat{
+     ans <- (log(a0)-digamma(a0)-s)
+     a1 <- a0-ans/(1.0/a0-trigamma(a0))
+     if(abs(ans) <= 1.0e-7 | l >= 30){break}
+     a0 <- a1
+     l <- l+1}
+   ah <- a1; bh <- xb/a1
+   return(c(ah,bh))
+ }
> 
> #Computing prior hyperparameters for beta, the size effect
> prior_empBayes_forbeta <- function(xs,ys,zs){
+   #Function to compute the hyperparameters of the gamma distribution for
+   #beta_1,...beta_K~beta(a_beta,b_beta) with b_beta~gamma(a_b_beta,b_b_beta)
+   bbeta_est <- (xs+ys+zs)/2
+   bbeta_est[which(bbeta_est==0)] <- 0.1
+   tem <- gam.mles.data(bbeta_est) #MLE of the gamma function but it is parameterized so that E(x)=ab if x~gamma(a,b)
+   tem[1] <- min(max(tem[1],10^(-3)),10^5)
+   tem[2] <- min(max(tem[2],10^(-3)),10^5)  #Our gamma parameterization is E(x)=a/b
+   a_beta <- tem[1]
+   a_b_beta <- 2*tem[2]^(-1)#
+   b_b_beta <- 2
+   return(list(a_beta=a_beta, a_b_beta=a_b_beta, b_b_beta=b_b_beta))
+ }
> 
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ tibble  3.0.4     ✔ dplyr   1.0.2
✔ tidyr   1.1.2     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
✔ purrr   0.3.4     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ tidyr::extract() masks rstan::extract()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
> mydata <- as_tibble(read.csv(data.file))
> 
> for (gene in 1:nrow(mydata))
+ {
+   
+   nreps <- mydata[gene,] %>% dplyr::select(ends_with("num_reps"))
+   nconditions <- length(nreps)            #Number of environments
+   seqI<-nreps
+   allI<-as.vector(seqI)  
+   cat("seqI is")
+   print(seqI)
+   
+   xs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g1")))
+   ys <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g2")))
+   zs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("both")))
+   xactiveflag <- unlist(mydata[gene,] %>% dplyr::select(contains("flag_analyze")))
+   print(xs)
+   print(ys)
+   print(zs)
+   #If at least one flaganalyze is 0 we fill the results wiht NA and go to the next
+   if(prod(xactiveflag)==0)
+   {
+     howmanyNA<-length(unlist(strsplit(headers_out,",")))-2
+ 	out=paste("line", "fusion_id", rep(NA,howmanyNA,collapse=","),sep=",")
+   cat(out,file=fileout,append=TRUE,sep="\n")
+   next
+   }
+   q_sim <- matrix(unlist((mydata[gene, ]%>% dplyr::select(starts_with("prior")))), nrow=length(nreps), byrow =TRUE, ncol=2)
+   
+   hyper_beta <- prior_empBayes_forbeta(xs, ys, zs)
+   #Making the data ready for stan
+   datastan <- list(K = sum(seqI),                 #Total number of bioresps
+ 	    n_environment = nconditions,         #Number of environments, so far 2.
+ 	    xenv = rep(seq(1,length(seqI)),seqI),       #Environment index 
+ 	    xs = as.vector(xs),
+ 	    ys = as.vector(ys),
+ 	    zs = as.vector(zs),
+ 	    r = q_sim,  #matrix of systematic bias corrections
+ 	    a_beta = hyper_beta$a_beta,               #Set to MLE under the null model
+ 	    a_b_beta = hyper_beta$a_b_beta,           #b_beta~gamma(a_b_beta,b_b_beta)
+ 	    b_b_beta = hyper_beta$b_b_beta,
+ 	    a_overdispersion = 2.01,#1,
+ 	    b_overdispersion = 0.05 #100, #phi is apriori small, if inverse gamma is used prior mean b_phi/(a_phi-1)
+ 	 )
+   
+   starting_values  <-  function(){ ###Not actually needed according to Luis
+     out <- with(datastan, list(overdispersion=0.01, bbeta=xs+ys+zs, alpha=rep(1.0,n_environment)))
+     return(out)
+   }
+ 
+ 	totalcounts=
+ 	rbind(
+ 	xs=tapply(datastan$xs,FUN=sum,INDEX=datastan$xenv),
+ 	ys=tapply(datastan$ys,FUN=sum,INDEX=datastan$xenv),
+ 	zs=tapply(datastan$zs,FUN=sum,INDEX=datastan$xenv)
+ 	)
+   
+   cat("datastan is")
+   print(datastan)
+ 
+   fit1 <-rstan::stan(
+     file = "environmentalmodel2.stan", # Stan program
+ 	  data = datastan,    # named list of data
+ 	  chains = 1,             # number of Markov chains
+ 	  warmup = nburnin,          # number of warmup iterations per chain
+ 	  thin = save.sample.freq,
+ 	  iter = niter,            # total number of iterations per chain
+ 	  refresh = reporting.freq,             # no progress shown if this is 0
+ 	  init = "starting_values",
+ 	  control = list(adapt_delta = stepsize)  # The bigger the value the smaller the step size
+ 	  #pars=c("alpha","sigma_alpha")
+ 	  #c("bbeta","alpha","overdispersion","theta","sigma_alpha") 
+    )
+ 	
+    # fig.dir <- paste0(unlist(strsplit(out.dir, "/g3_sim_output"))[1], "/data_visualization")
+    # jpeg(paste0(fig.dir,"/diagnostic_plots_stan4c_", gsub(".csv", "", tail(unlist(strsplit(fileout, "/")), 1)),".jpeg"))
+    # rstan::pairs(fit1)
+    # dev.off()
+   
+   theta<-rstan::extract(fit1,pars="theta")$theta #Estimated proportion of reads aligning to tester in mated after adjusting for systematic bias
+   alpha<-rstan::extract(fit1,pars=c("alpha"))$alpha
+   Stanresults=matrix(NA,nrow=nconditions,ncol=4)
+   Bayes_AI_pvalue<-rep(NA,nconditions)
+   for(mystan in 1:nrow(Stanresults)) {
+     theta1<-theta[,mystan]
+     alpha1<-alpha[,mystan]
+     Stanresults[mystan,]<-c(mean(theta1), quantile(theta1,c(0.025,0.975)),2*min(mean(theta1>1/2),mean(theta1<1/2))) 
+     Bayes_AI_pvalue[mystan]<-2*min(c(mean(alpha1>1),mean(alpha1<1)))
+   }
+   colnames(Stanresults)=c("mean","q_025","q_975","AIbayesian-pva")
+   cat("Stanresults",Stanresults,"\n")
+   Stanresults[,"AIbayesian-pva"]
+   
+   for(repcond in 1:nconditions) {
+     theta1<-theta[,repcond]
+     smallStanres<-paste(round(totalcounts[row.names(totalcounts)=="xs",repcond]/(totalcounts[row.names(totalcounts)=="xs",repcond]+totalcounts[row.names(totalcounts)=="ys",repcond]),4),
+                         round(mean(theta1),4),
+                         paste(round(quantile(theta1,c(0.025,0.975)),4),collapse=","),
+                         round(Bayes_AI_pvalue[repcond],4),
+                         ifelse(Bayes_AI_pvalue[repcond]<0.05,1,0),sep=",")
+     if(repcond==1) fullStanres<-smallStanres else fullStanres<-paste(fullStanres,smallStanres,sep=",",collapse=",")
+   }
+   alpha1greateralpha2<-NA 
+   #alpha1greateralpha2 is the bayesian independence test. Only meaningful for two conditions
+   if(nconditions==2) {
+     alpha1greateralpha2<-round(min(mean(alpha[,1]>alpha[,2]),mean(alpha[,1]<alpha[,2]))*2,4)
+   }
+   
+   out=paste("line", "fusion_id", paste(allI,collapse=","), 
+             paste(apply(totalcounts,2,paste,collapse=","),collapse=","),
+             paste(t(datastan$r),collapse=","),
+             alpha1greateralpha2,
+             fullStanres,
+             paste(round(apply(alpha,2,mean),4),collapse=","),
+ 			paste(xactiveflag,collapse=","),
+             sep=",")
+   print(xactiveflag)
+   cat(out,file=fileout,append=TRUE,sep="\n")
+   print(unlist(strsplit(headers_out,",")))
+   print(unlist(strsplit(out,",")))
+ }
seqI is# A tibble: 1 x 1
  c1_num_reps
        <int>
1           3
counts_c1_g1_rep1 counts_c1_g1_rep2 counts_c1_g1_rep3 
               48                39                22 
counts_c1_g2_rep1 counts_c1_g2_rep2 counts_c1_g2_rep3 
              163               200               120 
counts_c1_both_rep1 counts_c1_both_rep2 counts_c1_both_rep3 
                 72                  60                  24 
datastan is$K
[1] 3

$n_environment
[1] 1

$xenv
[1] 1 1 1

$xs
[1] 48 39 22

$ys
[1] 163 200 120

$zs
[1] 72 60 24

$r
     [,1] [,2]
[1,]  0.8  0.8

$a_beta
[1] 15.3942

$a_b_beta
[1] 0.2469657

$b_b_beta
[1] 2

$a_overdispersion
[1] 2.01

$b_overdispersion
[1] 0.05


SAMPLING FOR MODEL 'environmentalmodel2' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 2.6e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 1: Iteration: 1000 / 6000 [ 16%]  (Warmup)
Chain 1: Iteration: 2000 / 6000 [ 33%]  (Warmup)
Chain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 1: Iteration: 4000 / 6000 [ 66%]  (Sampling)
Chain 1: Iteration: 5000 / 6000 [ 83%]  (Sampling)
Chain 1: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.191219 seconds (Warm-up)
Chain 1:                0.201064 seconds (Sampling)
Chain 1:                0.392283 seconds (Total)
Chain 1: 
Stanresults 0.209204 0.1596346 0.2819778 0 
c1_flag_analyze 
              1 
 [1] "comparison"                     "FEATURE_ID"                    
 [3] "c1_num_reps"                    "counts_c1_g1"                  
 [5] "counts_c1_g2"                   "counts_c1_both"                
 [7] "prior_c1_g1"                    "prior_c1_g2"                   
 [9] "H3_independence_Bayes_evidence" "g1_c1_sampleprop"              
[11] "g1_c1_mean"                     "g1_c1_q025"                    
[13] "g1_c1_q975"                     "g1_c1_Bayes_evidence"          
[15] "g1_c1_AI_decision"              "alpha1_postmean"               
[17] "c1_flag_analyze"               
 [1] "line"      "fusion_id" "3"         "109"       "483"       "156"      
 [7] "0.8"       "0.8"       "NA"        "0.1841"    "0.2092"    "0.1596"   
[13] "0.282"     "0"         "1"         "1.9618"    "1"        
seqI is# A tibble: 1 x 1
  c1_num_reps
        <int>
1           3
counts_c1_g1_rep1 counts_c1_g1_rep2 counts_c1_g1_rep3 
               31                43                48 
counts_c1_g2_rep1 counts_c1_g2_rep2 counts_c1_g2_rep3 
              188               213                81 
counts_c1_both_rep1 counts_c1_both_rep2 counts_c1_both_rep3 
                 71                  64                  32 
datastan is$K
[1] 3

$n_environment
[1] 1

$xenv
[1] 1 1 1

$xs
[1] 31 43 48

$ys
[1] 188 213  81

$zs
[1] 71 64 32

$r
     [,1] [,2]
[1,]  0.8  0.8

$a_beta
[1] 11.91772

$a_b_beta
[1] 0.1854897

$b_b_beta
[1] 2

$a_overdispersion
[1] 2.01

$b_overdispersion
[1] 0.05


SAMPLING FOR MODEL 'environmentalmodel2' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 1: Iteration: 1000 / 6000 [ 16%]  (Warmup)
Chain 1: Iteration: 2000 / 6000 [ 33%]  (Warmup)
Chain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 1: Iteration: 4000 / 6000 [ 66%]  (Sampling)
Chain 1: Iteration: 5000 / 6000 [ 83%]  (Sampling)
Chain 1: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.198748 seconds (Warm-up)
Chain 1:                0.223559 seconds (Sampling)
Chain 1:                0.422307 seconds (Total)
Chain 1: 
Stanresults 0.2585604 0.1800304 0.3754211 0.001333333 
c1_flag_analyze 
              1 
 [1] "comparison"                     "FEATURE_ID"                    
 [3] "c1_num_reps"                    "counts_c1_g1"                  
 [5] "counts_c1_g2"                   "counts_c1_both"                
 [7] "prior_c1_g1"                    "prior_c1_g2"                   
 [9] "H3_independence_Bayes_evidence" "g1_c1_sampleprop"              
[11] "g1_c1_mean"                     "g1_c1_q025"                    
[13] "g1_c1_q975"                     "g1_c1_Bayes_evidence"          
[15] "g1_c1_AI_decision"              "alpha1_postmean"               
[17] "c1_flag_analyze"               
 [1] "line"      "fusion_id" "3"         "122"       "482"       "167"      
 [7] "0.8"       "0.8"       "NA"        "0.202"     "0.2586"    "0.18"     
[13] "0.3754"    "0.0013"    "1"         "1.7204"    "1"        
> 
are_q_equal Y
qsim1 0.8
qmodel1 0.8

R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> what.to.do <- (commandArgs(TRUE))
> if(length(what.to.do)>0)
+ {
+   data.file <- as.character(as.character(unlist(strsplit(what.to.do[1],"="))[2]))
+   q.model.g1 <- as.numeric(as.character(unlist(strsplit(what.to.do[2],"="))[2]))
+   q.model.g2 <- as.numeric(unlist(strsplit(what.to.do[3],"="))[2])
+   stan.program <- as.character(unlist(strsplit(what.to.do[4],"="))[2])
+   niter <- as.numeric(as.character(unlist(strsplit(what.to.do[5],"="))[2]))
+   nburnin <- as.numeric(as.character(unlist(strsplit(what.to.do[6],"="))[2]))
+   save.sample.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[7],"="))[2]))
+   reporting.freq <- as.numeric(as.character(unlist(strsplit(what.to.do[8],"="))[2]))
+   stepsize <- as.numeric(as.character(unlist(strsplit(what.to.do[9],"="))[2]))
+   nconditions<- as.numeric(as.character(unlist(strsplit(what.to.do[10],"="))[2]))
+ }
> 
> out.dir <- dirname(data.file)
> print(out.dir)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_null"
> 
> base.out<-paste(gsub(".csv","",basename(data.file)), 
+                                  stan.program,
+                                  'qmodel_g1', q.model.g1, 'qmodel_g2', q.model.g2, 
+                                  'iterations', niter, 'burnin', nburnin, 
+                                  'thin', save.sample.freq, 'refresh', reporting.freq, 
+                                  'stepsize', stepsize, sep="_")
> fileout <- paste(paste(out.dir, base.out, sep = "/"),".csv",sep="")
> print(fileout)
[1] "/blue/mcintyre/fabio.marroni/git_BASE_2020/BASE_2020/simulation//g3_sim_output/H1_not_null_H2_not_null_H3_null/out_alpha_2_delta_2_qsim_g1_0.8_qsim_g2_0.8_mult_1_myreads_100_simruns_2_stan4c_qmodel_g1_0.8_qmodel_g2_0.8_iterations_6000_burnin_3000_thin_1_refresh_1000_stepsize_0.99.csv"
> 
> #########################
> #Trying to generalize to an arbitrary number of conditions
> #########################
> 
> seqcond<-paste("c",seq(1,nconditions),sep="")
> fornames1=paste("g1_",seqcond,sep="") #Tester given condition
> fornames2 <- c("sampleprop", "mean", "q025", "q975", "Bayes_evidence", "AI_decision")
> fornames=paste(paste(rep(fornames1,each=length(fornames2)),fornames2,sep="_"),collapse=",")
> #The three possible alignment states: better to tester (G1?), better to line (G2?), equally good (both).
> #alnto<-c("g1","g2","Both")
> counttester<-paste("counts_",seqcond,"_g1",sep="")
> countline<-paste("counts_",seqcond,"_g2",sep="")
> countboth<-paste("counts_",seqcond,"_both",sep="")
> countheader<-paste(counttester,countline,countboth,sep=",",collapse=",")
> priorstester<-paste("prior_",seqcond,"_g1",sep="")
> priorsline<-paste("prior_",seqcond,"_g2",sep="")
> allpriors<-sort(c(priorstester,priorsline))
> seqreps<-paste(seqcond,"_num_reps",sep="")
> activeflag<-paste(seqcond,"flag_analyze",sep="_")
> firstheaders=paste(c("comparison","FEATURE_ID",
+                      seqreps,
+                      countheader,
+                       allpriors, 
+ 					  "H3_independence_Bayes_evidence",
+ 					  "probofsameAI"),
+                       collapse=",")
> 
> alpha_post_names<-paste(paste("alpha",seq(1,nconditions),"_postmean",sep=""),collapse=",")
> cat("alpha names are:",alpha_post_names,"\n")
alpha names are: alpha1_postmean 
> cat("stan4 firstheaders are:",firstheaders,"\n")
stan4 firstheaders are: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence,probofsameAI 
> headers_out=paste(firstheaders,fornames,alpha_post_names,"sigma_alpha_mean","sigma_alpha_0.5","sigma_alpha_0.95",paste(activeflag,collapse=","),sep=",")
> cat("stan4 headers_out is:",headers_out,"\n")
stan4 headers_out is: comparison,FEATURE_ID,c1_num_reps,counts_c1_g1,counts_c1_g2,counts_c1_both,prior_c1_g1,prior_c1_g2,H3_independence_Bayes_evidence,probofsameAI,g1_c1_sampleprop,g1_c1_mean,g1_c1_q025,g1_c1_q975,g1_c1_Bayes_evidence,g1_c1_AI_decision,alpha1_postmean,sigma_alpha_mean,sigma_alpha_0.5,sigma_alpha_0.95,c1_flag_analyze 
> cat(headers_out,file=fileout,append=FALSE,sep="\n")
> 
> 
> #End of arguments and names copied from the scripts used for the analysis of real data
> 
> #The special thing about this function is that it is able to accept a multiplicative factor for the estimation of the reads aligning on both genomes, to see how misspecification of that quantity affects results
> options(warn=1)
> 
> library("rstan")
Loading required package: StanHeaders
Loading required package: ggplot2
rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
> rstan_options(auto_write = FALSE)
> gam.mles.data <- function(x){
+   # CALCULATION OF THE MLES for gamma  GIVEN THE SAMPLE
+   n <- length(x)
+   xb <- mean(x)
+   xd <- mean(log(x))
+   s <- log(xb)-xd
+   a0 <- (3.0-s+sqrt((s-3.0)^2+24.0*s))/12.0/s
+   l <- 1
+   repeat{
+     ans <- (log(a0)-digamma(a0)-s)
+     a1 <- a0-ans/(1.0/a0-trigamma(a0))
+     if(abs(ans) <= 1.0e-7 | l >= 30){break}
+     a0 <- a1
+     l <- l+1}
+   ah <- a1; bh <- xb/a1
+   return(c(ah,bh))
+ }
> 
> #Computing prior hyperparameters for beta, the size effect
> prior_empBayes_forbeta <- function(xs,ys,zs){
+   #Function to compute the hyperparameters of the gamma distribution for
+   #beta_1,...beta_K~beta(a_beta,b_beta) with b_beta~gamma(a_b_beta,b_b_beta)
+   bbeta_est <- (xs+ys+zs)/2
+   bbeta_est[which(bbeta_est==0)] <- 0.1
+   tem <- gam.mles.data(bbeta_est) #MLE of the gamma function but it is parameterized so that E(x)=ab if x~gamma(a,b)
+   tem[1] <- min(max(tem[1],10^(-3)),10^5)
+   tem[2] <- min(max(tem[2],10^(-3)),10^5)  #Our gamma parameterization is E(x)=a/b
+   a_beta <- tem[1]
+   a_b_beta <- 2*tem[2]^(-1)#
+   b_b_beta <- 2
+   return(list(a_beta=a_beta, a_b_beta=a_b_beta, b_b_beta=b_b_beta))
+ }
> 
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ tibble  3.0.4     ✔ dplyr   1.0.2
✔ tidyr   1.1.2     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
✔ purrr   0.3.4     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ tidyr::extract() masks rstan::extract()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
> mydata <- as_tibble(read.csv(data.file))
> 
> for (gene in 1:nrow(mydata))
+ {
+   
+   nreps <- mydata[gene,] %>% dplyr::select(ends_with("num_reps"))
+   nconditions <- length(nreps)            #Number of environments
+   seqI<-nreps
+   allI<-as.vector(seqI)  
+   cat("seqI is")
+   print(seqI)
+  
+   xs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g1")))
+   ys <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("g2")))
+   zs <- unlist(mydata[gene,] %>% dplyr::select(starts_with("counts")) %>% dplyr::select(contains("both")))
+   xactiveflag <- unlist(mydata[gene,] %>% dplyr::select(contains("flag_analyze")))
+   print(xs)
+   print(ys)
+   print(zs)
+   #If at least one flaganalyze is 0 we fill the results wiht NA and go to the next
+   if(prod(xactiveflag)==0)
+   {
+     howmanyNA<-length(unlist(strsplit(headers_out,",")))-2
+ 	out=paste("line", "fusion_id", rep(NA,howmanyNA,collapse=","),sep=",")
+     cat(out,file=fileout,append=TRUE,sep="\n")
+     next
+   }
+   q_sim <- matrix(unlist((mydata[gene, ]%>% dplyr::select(starts_with("prior")))), nrow=length(nreps), byrow =TRUE, ncol=2)
+   
+   hyper_beta <- prior_empBayes_forbeta(xs, ys, zs)
+   #Making the data ready for stan
+   datastan <- list(K = sum(seqI),                 #Total number of bioresps
+ 	    n_environment = nconditions,         #Number of environments, so far 2.
+ 	    xenv = rep(seq(1,length(seqI)),seqI),       #Environment index 
+ 	    xs = as.vector(xs),
+ 	    ys = as.vector(ys),
+ 	    zs = as.vector(zs),
+ 	    r = q_sim,  #matrix of systematic bias corrections
+ 	    a_beta = hyper_beta$a_beta,               #Set to MLE under the null model
+ 	    a_b_beta = hyper_beta$a_b_beta,           #b_beta~gamma(a_b_beta,b_b_beta)
+ 	    b_b_beta = hyper_beta$b_b_beta,
+ 	    a_overdispersion = 2.01,#1,
+ 	    b_overdispersion = 0.05 #100, #phi is apriori small, if inverse gamma is used prior mean b_phi/(a_phi-1)
+ 	 )
+   
+   starting_values  <-  function(){ ###Not actually needed according to Luis
+     out <- with(datastan, list(overdispersion=0.01, bbeta=xs+ys+zs, alpha=rep(1.0,n_environment)))
+     return(out)
+   }
+ 
+ 	totalcounts=
+ 	rbind(
+ 	xs=tapply(datastan$xs,FUN=sum,INDEX=datastan$xenv),
+ 	ys=tapply(datastan$ys,FUN=sum,INDEX=datastan$xenv),
+ 	zs=tapply(datastan$zs,FUN=sum,INDEX=datastan$xenv)
+ 	)
+   
+   datastan4c <- datastan
+   datastan4c$c_sigma_alpha <- c(NA,0.01760,0.01472,0.01343,0.01265 )[datastan4c$n_environment]#Constants depends on number of environments
+   cat("datastan is")
+   print(datastan4c)
+ 
+   fit1 <-rstan::stan(
+     file = "environmentalmodel4c.stan", # Stan program
+ 	  data = datastan4c,    # named list of data
+ 	  chains = 1,             # number of Markov chains
+ 	  warmup = nburnin,          # number of warmup iterations per chain
+ 	  thin = save.sample.freq,
+ 	  iter = niter,            # total number of iterations per chain
+ 	  refresh = reporting.freq,             # no progress shown
+ 	  init = "starting_values",
+ 	  control = list(adapt_delta = stepsize)  # The bigger the value the smaller the step size
+ 	  #pars=c("alpha","sigma_alpha")
+ 	  #c("bbeta","alpha","overdispersion","theta","sigma_alpha") 
+    )
+ 	
+    # fig.dir <- paste0(unlist(strsplit(out.dir, "/g3_sim_output"))[1], "/data_visualization")
+    # jpeg(paste0(fig.dir,"/diagnostic_plots_stan4c_", gsub(".csv", "", tail(unlist(strsplit(fileout, "/")), 1)),".jpeg"))
+    # rstan::pairs(fit1)
+    # dev.off()
+   
+ 	palphasequal <- rstan::extract(fit1,pars=c("palphasequal"))$palphasequal
+ 	theta <- rstan::extract(fit1,pars="theta")$theta #Estimated proportion of reads aligning to tester in mated after adjusting for systematic bias
+ 	alpha <- rstan::extract(fit1,pars=c("alpha"))$alpha
+ 	sigma_alpha <- rstan::extract(fit1,pars=c("sigma_alpha"))$sigma_alpha
+ 	
+ 	Stanresults <- matrix(NA,nrow=nconditions,ncol=4)
+ 	Bayes_AI_pvalue <- rep(NA,nconditions)
+ 	for(mystan in 1:nrow(Stanresults)) {
+ 	  theta1 <- theta[,mystan]
+ 	  alpha1 <- alpha[,mystan]
+     Stanresults[mystan,]<-c(mean(theta1), quantile(theta1,c(0.025,0.975)),2*min(mean(theta1>1/2),mean(theta1<1/2))) 
+ 	Bayes_AI_pvalue[mystan] <- 2*min(c(mean(alpha1>1), mean(alpha1<1)))
+ 	} 
+ 	
+ 	colnames(Stanresults) <- c("mean", "q_025", "q_975", "AIbayesian-pval")
+ 	cat("Stanresults",Stanresults,"\n")
+ 	Stanresults[,"AIbayesian-pval"]
+ 
+ 	sigma_alpha_out <- c(mean(sigma_alpha), quantile(sigma_alpha, c(0.5,0.95))) #POSSIBLE bug: c(0.5,0.95) or c(0.05,0.95)? 
+ 
+ 	for(repcond in 1:nconditions) {
+ 	  theta1 <- theta[,repcond]
+ 	  smallStanres <- paste(round(totalcounts[row.names(totalcounts)=="xs", repcond]/(totalcounts[row.names(totalcounts)=="xs", repcond] + totalcounts[row.names(totalcounts)=="ys", repcond]), 4),
+ 	                        round(mean(theta1), 4),
+ 	                        paste(round(quantile(theta1, c(0.025,0.975)), 4), collapse=","),
+ 	                        round(Bayes_AI_pvalue[repcond], 4), 
+ 	                        ifelse(Bayes_AI_pvalue[repcond] < 0.05, 1, 0), sep=",")
+ 	  if(repcond==1) fullStanres <- smallStanres else fullStanres <- paste(fullStanres, smallStanres, sep=",", collapse=",")
+ 	}
+ 	
+ 	alpha1greateralpha2 <- NA
+ 	#alpha1greateralpha2 is the bayesian independence test. Only meaningful for two conditions
+ 	if(nconditions==2) {
+ 	  alpha1greateralpha2 <- min(tem<-mean(alpha[,1]-alpha[,2]<0),1-tem)*2
+ 	}
+ 
+ 	probofsameAI <- mean(palphasequal)    
+ 	
+ 	totalcounts <- rbind(xs <- tapply(datastan$xs, FUN=sum, INDEX=datastan$xenv),
+ 	                     ys <- tapply(datastan$ys, FUN=sum, INDEX=datastan$xenv),
+ 	                     zs <- tapply(datastan$zs, FUN=sum, INDEX=datastan$xenv))
+ 	
+ 	out <- paste("line", "fusion_id", paste(allI,collapse=","),
+ 	             paste(apply(totalcounts, 2, paste, collapse=","), collapse=","),
+ 				 paste(t(datastan$r),collapse=","),
+ 	             alpha1greateralpha2,
+ 	             probofsameAI,
+ 	             fullStanres,
+ 	             paste(round(apply(alpha,2,mean),4),collapse=","),
+ 	             paste(round(sigma_alpha_out,6),collapse=","),
+ 				 paste(xactiveflag,collapse=","),
+ 	             sep=",")
+     print(xactiveflag)
+ 	cat(out, file=fileout, append=TRUE, sep="\n")
+     print(unlist(strsplit(headers_out,",")))
+     print(unlist(strsplit(out,",")))
+ 
+ }
seqI is# A tibble: 1 x 1
  c1_num_reps
        <int>
1           3
counts_c1_g1_rep1 counts_c1_g1_rep2 counts_c1_g1_rep3 
               48                39                22 
counts_c1_g2_rep1 counts_c1_g2_rep2 counts_c1_g2_rep3 
              163               200               120 
counts_c1_both_rep1 counts_c1_both_rep2 counts_c1_both_rep3 
                 72                  60                  24 
datastan is$K
[1] 3

$n_environment
[1] 1

$xenv
[1] 1 1 1

$xs
[1] 48 39 22

$ys
[1] 163 200 120

$zs
[1] 72 60 24

$r
     [,1] [,2]
[1,]  0.8  0.8

$a_beta
[1] 15.3942

$a_b_beta
[1] 0.2469657

$b_b_beta
[1] 2

$a_overdispersion
[1] 2.01

$b_overdispersion
[1] 0.05

$c_sigma_alpha
[1] NA

Error in FUN(X[[i]], ...) : 
  Stan does not support NA (in c_sigma_alpha) in data
failed to preprocess the data; sampling not done
Stan model 'environmentalmodel4c' does not contain samples.
Stan model 'environmentalmodel4c' does not contain samples.
Stan model 'environmentalmodel4c' does not contain samples.
Stan model 'environmentalmodel4c' does not contain samples.
Warning in mean.default(theta1) :
  argument is not numeric or logical: returning NA
Stanresults NA NA NA NaN 
Warning in mean.default(sigma_alpha) :
  argument is not numeric or logical: returning NA
Warning in mean.default(theta1) :
  argument is not numeric or logical: returning NA
Warning in mean.default(palphasequal) :
  argument is not numeric or logical: returning NA
Error in apply(alpha, 2, mean) : dim(X) must have a positive length
Calls: paste -> paste -> apply
Execution halted
